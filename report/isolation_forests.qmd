
```{python}
import os
import numpy as np
import pandas as pd
import sklearn as sk
import shap
import os
import sys
from datetime import datetime
from sklearn.ensemble import IsolationForest

sys.path.append(os.getcwd())
sys.path.append(os.path.dirname(os.getcwd()))

import scripts.cons as cons
```

# Data Load

```{python}
# load random telecom payments data
filepath_or_buffer=os.path.join('..', 'data', 'RandomTelecomPayments.csv')
parse_dates = ['registration_date', 'transaction_date']
date_parser = lambda x: datetime.strptime(x, '%Y-%m-%d')
data = pd.read_csv(filepath_or_buffer=filepath_or_buffer,  parse_dates=parse_dates)

# determine the week number for all transaction dates
data['transaction_week'] = data['transaction_date'].dt.isocalendar().week
```

# Feature Engineering

Count of transaction status and transaction error codes in last 7 days

```{python}
def feature_engineer(data, ids, groups, target, func):
    """
    """
    # aggregate across the ids and group, applying the function to the target
    data_agg = data.copy().groupby(by=ids+groups, as_index=False).agg({target:func})
    # pivot the target results across each group
    data_pivot = pd.pivot_table(data=data_agg, index=ids, values=target, columns=groups)
    # rename and format the columns
    data_pivot.columns = data_pivot.columns.str.split(':').str[0] + f'_{func}'
    data_pivot = data_pivot.reset_index()
    data_pivot.columns.name = None
    return data_pivot

# engineer features
userid_cnt_data = feature_engineer(data=data, ids=['userid', 'transaction_week'], groups=['transaction_error_code'], target='transaction_amount', func='size')
userid_sum_data = feature_engineer(data=data, ids=['userid', 'transaction_week'], groups=['transaction_error_code'], target='transaction_amount', func='sum')
# create base data
base_data = pd.merge(
    left=userid_cnt_data[['userid', 'transaction_week', 'E900_size']], 
    right=userid_sum_data[['userid', 'transaction_week', 'E900_sum']], 
    on=['userid', 'transaction_week'], 
    how='outer'
    )
# fill in zero values
base_data = base_data.fillna(0)
```

# Isolation Forests Model

```{python}
# train isolation forests
id_cols = ['userid', 'transaction_week']
X_cols = ['E900_size', 'E900_sum']
train_data = base_data[X_cols].copy()
clf = IsolationForest(random_state=0).fit(train_data)

# score data
score_data = base_data[id_cols+X_cols].copy()
score_data['score'] = clf.decision_function(train_data)
score_data.sort_values(by='score')
```