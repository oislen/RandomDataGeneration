
```{python}
import os
import numpy as np
import pandas as pd
import os
import sys

sys.path.append(os.getcwd())
sys.path.append(os.path.dirname(os.getcwd()))

import scripts.cons as cons
```

# Data Load

```{python}
# load random telecom payments data
filepath_or_buffer=os.path.join('..', 'data', 'RandomTelecomPayments.csv')
parse_dates = ['registration_date', 'transaction_date']
date_parser = lambda x: datetime.strptime(x, '%Y-%m-%d')
data = pd.read_csv(filepath_or_buffer=filepath_or_buffer,  parse_dates=parse_dates)

# determine the week number for all transaction dates
data['transaction_week'] = data['transaction_date'].dt.isocalendar().week
```

# Feature Engineering

Count of successful transactions in last 7 days

```{python}
def feature_engineer(data, ids, groups, target, func):
    """
    """
    data_agg = data.copy().groupby(by=ids+groups, as_index=False).agg({target:func})
    data_pivot = pd.pivot_table(data=data_agg, index=ids, values=target, columns=groups)
    data_pivot.columns = '_'.join(ids+groups) + '_' + data_pivot.columns.str.split(':').str[0] + f'_{func}'
    return data_pivot

# engineer features
userid_cnt_data = feature_engineer(data=data, ids=['userid'], groups=['transaction_status'], target='transaction_amount', func='size')
userid_sum_data = feature_engineer(data=data, ids=['userid'], groups=['transaction_status'], target='transaction_amount', func='sum')
# determine the base dataset
groupby_cols = ['userid', 'transaction_week']
agg_dict = {'transaction_amount':'sum'}
base_data = data.groupby(groupby_cols, as_index=False).agg(agg_dict)
# join user features
base_data = base_data.merge(userid_cnt_data, how='left', on='userid')
base_data = base_data.merge(userid_sum_data, how='left', on='userid')
# fill in zero values
base_data = base_data.fillna(0)
# subset required data
id_cols = ['userid', 'transaction_week']
X_cols = ['userid_transaction_status_successful_size', 'userid_transaction_status_successful_sum']
base_data = base_data[id_cols+X_cols].sort_values(by=['userid','transaction_week']).copy()
```


# Customer Value Score

```{python}
def week_pct_score(group):
    """
    """
    score_cols = ['userid_transaction_status_successful_size','userid_transaction_status_successful_sum']
    group_score = group[score_cols].rank(method='average', ascending=True, pct=True, axis=0)
    group_score.columns = group_score.columns + '_pct'
    group_results = group.join(group_score)
    return group_results

# score each user across each week for their percentile score in number of successfull transactions counts and acounts
score_data_week = base_data.groupby(by=['transaction_week'], group_keys=False).apply(lambda group: week_pct_score(group))
# aggregate across dataset to find most valueable users
agg_dict={'userid_transaction_status_successful_size':'sum', 'userid_transaction_status_successful_sum':'sum', 'userid_transaction_status_successful_size_pct':'sum', 'userid_transaction_status_successful_sum_pct':'sum'}
score_data_total = score_data_week.groupby(by=['userid']).agg(agg_dict).sort_values(by=['userid_transaction_status_successful_sum_pct'], ascending=False)
```